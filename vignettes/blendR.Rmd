---
title: "BlendR: Combining a Probability and a Non-Probability Sample in a Capture-Recapture Setting"
author: "Benjamin Williams"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{BlendR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

##Introduction 
This package provides several estimators of total for combining a non-probability sample with a probability sample.  In general, probability samples are preferred to non-probability samples because the sampling variance of the estimators calculated from probability samples can be determined using standard sampling theory. Even non-sampling errors, such as non-response bias, may be easier to assess and mitigate for probability samples. The primary disadvantage of non-probability samples is the potential for biased estimation stemming from undercoverage and a lack of representativeness in the samples. Without external sources of information, these sample deficiencies cannot be detected.

In reality, it is usually easier to obtain a non-probability sample than a probability sample. For example, a frame may not be available, which complicates the selection of a probability sample. A non-probability sample, such as one using data from volunteers, does not require an expensive nonresponse follow-up. The larger the sample, the more information it may contain. This is an attractive option for analysts working with limited resources while studying elusive populations. As a result, statisticians have begun to investigate methods for improving estimation using data from non-probability samples.

There are many ways of combining data, but in this package the data is combined under assumptions of a capture-recapture model. 

##Capture-Recapture Methodology

Capture-recapture methods are powerful ways to estimate total in specific scenarios. In a classic example, suppose a researcher wishes to know the total number of fish ($N$) in the local fishing hole. On the initial fishing trip, she catches $n_1$ fish. These fish are tagged so they can be identified later. The next day she returns to the same fishing hole and catches $n_2$ fish. In this second catch, suppose $m$ fish were also caught on the first day, identifiable by their tag. If the proportion of tagged fish in the second sample is approximately equal to the proportion of tagged fish in the population of fish, then $E(\frac{n_1}{N}) \approx  \frac{m}{n_2}$. This leads to the Lincoln-Peterson estimator of total Le Cren (1965): $$\hat{N} = \frac{n_1 n_2}{m}$$.

$\hat{N}$ is the maximum likelihood estimator of $N$ under the hypergeometric model, which assumes the recapture sample is a simple random sample (SRS). This SRS assumption does not necessarily extend to the initial sample. 

##Sampling Set-up
The estimators from this package assume the non-probability sample is analogous to the initial capture sample, while the probability sample acts as the recapture sample. For the estimators used in this package, the data must be gathered in such a way that units in some non-probability sample may be gathered into the probability sample with some positive, known probability. Each sample must record the same variable of interest, though this is not required for the first estimator below.

Define the universe of interest to be made up of $N$ units and call the population $U$. Call the probability sample $s_2$ and the non-probability sample $d_1$, since it can be thought of as a domain. There are $n_2$ units sampled in $s_2$ and $n_1$ units captured in the non-probability sample $d_1$. Denote by $m$ the number of units present in both $d_1$ and $s_2$. Then the number of units in $d_1$ only is $n_1 - m$, and the number of units in $s_2$ only is $n_2-m$. The objective is to estimate $t_y$ from the data from the two samples, when $N$ is unknown. 

Define the variable of interest for each unit in the population as $y_i$ ($i = 1,...,N$). Thus the goal is to estimate $t_y = \sum_{i=1}^{N}y_i$. In the non-probility sample, the variable of interest for the $i^{th}$ unit is denoted $y^*_i$.

If the $i^{th}$ unit is not a part of the non-probability sample, $y^*_i$ is defined to be 0. $y_i$ is distinguished from $y^*_i$ as measurement error or other non-sampling errors.

The estimators included so far in this package are taken from Liu et al (2017) and are now described.

##Estimator 1

The first estimator is denoted $\hat{t}_{yp}$ and is a generalized version of an estimator developed by Pollock et al (1994). Their data consists of a probability sample of fishing docks where interviewers record fish catch by incoming boats and a voluntary sample of trip counts (but not catch) self-reported by fishing captains. In this method the capture and the recapture samples are used to estimate the total number of trips $N$, which is then multiplied by an estimate of mean catch, determined from the recapture sample only :
$$\hat{t}_{yp} = \hat{N}\hat{\bar{y}}$$ where $\hat{N}$ is defined above for a capture-recapture setting and $\hat{\bar{y}}$ is the average catch from the probability intercept sample Pollock et al (1994). The expected value of this estimator is equal to $t_y$ when the intercept sample is a SRS of $U$.

Liu et al generalizes this estimator for a complex sample design with sampling weights: 
$$ \hat{t}_{yp}=\frac{n_1}{\hat{p}_1}\hat{\bar{y}}=n_1\frac{\hat{t}_y}{\hat{n}_1} $$
where $r_i$ is an indicator of whether a unit is a member of the non-probability sample
\[r_i = 
\begin{cases}
	1 & \text{if $i$ $\in$ $d_1$}\\
	0 & \text{otherwise}\\
\end{cases}
\]
and $\hat{n}_1=\sum_{i \in s_2}w_ir_i$, $\hat{p}_1=\frac{\sum_{i \in s_2}^{}w_ir_i}{\sum_{i \in s_2}w_i}$, and $\frac{\hat{t}_y}{\hat{n}_1}=\frac{\sum_{i \in s_2}^{}w_iy_i}{\sum_{i \in s_2}w_ir_i}$ are Horvitz-Thompson estimators of $n_1$, $p_1=\frac{n_1}{N}$ (the rate that non-probability units are selected into the probability sample), and $\frac{t_y}{n_1}$, respectively. The $w_i's$ are sampling weights, computed as reciprocals of the selection probabilities. Then, $\hat{t}_{yp}$ is a ratio estimator with ratio $B_p=\frac{t_y}{n_1}$ and with $r_i$ as the auxiliary variable.

To use $\hat{t}_{yp}$, one only needs to know the values of the variable of interest from the probability sample, and whether or not that unit was also in the capture (non-probability) sample.


##Estimator 2
The next estimator uses the value of the variable of interest collected in the non-probability sample as an auxiliary variable:
$$\hat{t}_{yc}=t_{y^*}\frac{\hat{t}_y}{\hat{t}_{y^*}}$$
where $t_{y^*}=\sum_{i=1}^{n_1}r_i{y_i}^*$, $\hat{t}_y=\sum_{i \in s_2}w_iy_i$, and $\hat{t}_{y^*}=\sum_{i \in s_2}w_ir_i{y_i}^*$. $t_{y^*}$ is the total of the variable of interest for the entire non-probability sample, and $\hat{t}_{y^*}$ is its estimator. $\hat{t}_{yc}$ is also a ratio estimator with auxiliary variable $r_iy^*_i$ and ratio $B_c = \frac{t_y}{t_{y^*}}$. $\hat{t}_{yc}$ takes the form of a capture-recapture estimator and uses the values from the non-probability sample as auxiliary information.

In this package, `t_c()` is the function to use $\hat{t}_{yc}$. The paramater `recapture_total` is a vector of the value of the variable for each unit in the recapture (probability) sample. `captured_total` is a vector of the value of the variable for each unit in the capture (non-probability) sample. `survey_design` is a specified (possibly complex) survey design specified with `survey::svydesign()` [survey package](https://cran.r-project.org/web/packages/survey/survey.pdf). `na_remove` is set to `TRUE` as a default, and `total_from_capture` is a numeric value of the sum of all the values of the variable of interest from the capture sample ($t_{y^*}$).

##Estimator 3
The final estimator is a special case of a weighted combination of $\hat{t}_{yp}$ and $\hat{t}_{yc}$ called $t_{MR}$. 
$$\hat{t}_{MR}=(1-W_{SRS})\hat{t}_{yp}+W_{SRS}\hat{t}_{yc}$$
$\hat{t}_{MR}$ is a multivariate ratio estimator (Olkin, 1958). The optimal weight $W_{SRS}$ if the recapture sample were a SRS would be:
$$W_{SRS}=\frac{t_{y^*}}{t_y}\frac{S_{1,yy^*}}{S_{1y^*}^2}=\frac{t_{y^*}}{t_y}\frac{S_{1y}}{S_{1y^*}}R_{1,yy^*}$$
where $S_{1,yy^*}$ is the covariance of $y$ and $y^*$ in $d_1$, $S^2_{1y^*}$ is the variance of $y^*$ in $d_1$, $S_{1y}$ is the standard deviation of $y$ in $d_1$, and $R_{1,yy^*}$ is the correlation of $y$ and $y^*$ in $d_1$. 

In applications, $W_{SRS}$ will be unknown, but it can be consistently estimated by $$\hat{W}_{SRS} = \frac{t_{y*}}{\hat{t}_{yc}}.$$

When $\hat{W}_{SRS}$ is substituted for $W_{SRS}$, the resulting estimator simplifies to: $$ \hat{t}_{y2} = t_{y*} + \frac{n_1}{\hat{n}_1}(\hat{t}_y - \hat{t}_{y*}).$$

This estimator is proposed even for complex sample designs. $\hat{t}_{y2}$ adjusts the total of the variable of interest from the capture sample additively rather than multiplicatively, as $\hat{t}_{yc}$ does.  
